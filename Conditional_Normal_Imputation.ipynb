{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUX1umrmcwBlCKTY3+iW2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmfara/Adversarial-Debiasing-Enhanced/blob/main/Conditional_Normal_Imputation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Assumes that the feature you're imputing is normally distributed within each group."
      ],
      "metadata": {
        "id": "FT9L9wGaiRxj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OnjgrkViKa_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def conditional_normal_impute(df, target_col, group_cols):\n",
        "    \"\"\"\n",
        "    Impute missing values in a numerical column using group-wise normal distribution sampling.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Input data.\n",
        "    - target_col (str): Column with missing numerical values to impute.\n",
        "    - group_cols (str or list of str): Column(s) to group by (e.g., protected attributes).\n",
        "\n",
        "    Returns:\n",
        "    - df (pd.DataFrame): DataFrame with imputed values in target_col.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n",
        "\n",
        "    # Ensure group_cols is a list\n",
        "    if isinstance(group_cols, str):\n",
        "        group_cols = [group_cols]\n",
        "\n",
        "    # Group by intersectional group(s)\n",
        "    grouped = df.groupby(group_cols)\n",
        "\n",
        "    for group_keys, group_df in grouped:\n",
        "        group_mask = np.all(\n",
        "            [df[col] == val for col, val in zip(group_cols, [group_keys] if len(group_cols) == 1 else group_keys)],\n",
        "            axis=0\n",
        "        )\n",
        "        group_values = df.loc[group_mask, target_col]\n",
        "\n",
        "        mean = group_values.mean(skipna=True)\n",
        "        std = group_values.std(skipna=True)\n",
        "        na_mask = group_mask & df[target_col].isna()\n",
        "        n_missing = na_mask.sum()\n",
        "\n",
        "        if n_missing > 0 and not np.isnan(mean) and not np.isnan(std) and std > 0:\n",
        "            sampled = np.random.normal(loc=mean, scale=std, size=n_missing)\n",
        "            df.loc[na_mask, target_col] = sampled\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###One group column (e.g., gender):"
      ],
      "metadata": {
        "id": "JwXk1OwhiYMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_imputed = conditional_normal_impute(df, target_col='income', group_cols='gender')"
      ],
      "metadata": {
        "id": "n5hHFffxicxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Multiple group columns (e.g., gender + race):"
      ],
      "metadata": {
        "id": "-6DgDWnZiiZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_imputed = conditional_normal_impute(df, target_col='income', group_cols=['gender', 'race'])\n"
      ],
      "metadata": {
        "id": "Hf8XSzWFihaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the data is skewed, using a normal distribution for imputation (as in Conditional Normal Imputation) may produce unrealistic or biased values. In such cases, it's better to use imputation methods that respect the true distribution of the data."
      ],
      "metadata": {
        "id": "FB0uIt-Uiqsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Conditional Sampling from Empirical Distribution\n",
        "Instead of assuming normality, sample from the actual observed values within each group."
      ],
      "metadata": {
        "id": "FkRAprrnjIth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conditional_empirical_impute(df, target_col, group_cols):\n",
        "    \"\"\"\n",
        "    Impute missing numerical values by sampling from the empirical (observed) distribution\n",
        "    within group(s).\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n",
        "    if isinstance(group_cols, str):\n",
        "        group_cols = [group_cols]\n",
        "\n",
        "    grouped = df.groupby(group_cols)\n",
        "\n",
        "    for group_keys, group_df in grouped:\n",
        "        group_mask = np.all(\n",
        "            [df[col] == val for col, val in zip(group_cols, [group_keys] if len(group_cols) == 1 else group_keys)],\n",
        "            axis=0\n",
        "        )\n",
        "        group_values = df.loc[group_mask, target_col].dropna()\n",
        "        na_mask = group_mask & df[target_col].isna()\n",
        "\n",
        "        if not group_values.empty and na_mask.sum() > 0:\n",
        "            sampled = np.random.choice(group_values, size=na_mask.sum(), replace=True)\n",
        "            df.loc[na_mask, target_col] = sampled\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "yQrjPTlsjOvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Quantile-based Imputation\n",
        "Use group-wise quantiles (like median or IQR-based sampling) to impute values. This avoids the distortion caused by outliers in skewed data.\n",
        "\n"
      ],
      "metadata": {
        "id": "wrX8uTO9i-3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Model-Based Imputation (Advanced)\n",
        "Train a regression model per group to predict missing values from other features. This works well with complex, skewed, or nonlinear data â€” but requires more setup."
      ],
      "metadata": {
        "id": "JdKyrPA0jBvg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktJFkGKLiuXu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}